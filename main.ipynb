{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch \n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataloader import CollateFunctionSongDetection, SongDetectorDataClass\n",
    "\n",
    "\n",
    "collate_fn = CollateFunctionSongDetection(segment_length=4096)\n",
    "\n",
    "test_class = SongDetectorDataClass(\"/media/george-vengrovski/disk2/training_song_detector/labeled_song_dataset/test\", augment=False)\n",
    "test_loader = DataLoader(test_class, batch_size=24, shuffle=True, num_workers=16, collate_fn=collate_fn)\n",
    "\n",
    "train_class = SongDetectorDataClass(\"/media/george-vengrovski/disk2/training_song_detector/labeled_song_dataset/train\", augment=False)\n",
    "train_loader = DataLoader(train_class, batch_size=24, shuffle=True, num_workers=16, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s = next(iter(test_loader))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(_[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george-vengrovski/anaconda3/envs/tweetybert/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "from model import TweetyNet\n",
    "from trainer import Trainer \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = TweetyNet(hidden_size=32, rnn_dropout=0.2, num_classes=1, input_shape=(1, 512, 4096))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george-vengrovski/Documents/projects/tweety_net_song_detector/src/trainer.py:139: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, train_loader=train_loader, test_loader=test_loader, device=device, lr=1e-3, plotting=True, batches_per_eval=10, desired_total_batches=1, patience=8)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_model_config_and_weights\n",
    "\n",
    "config = {\n",
    "\"model_name\": \"sorter-specs-with-nothreshold-with-LLB-0.1\",\n",
    "\"hidden_size\": 32,\n",
    "\"context_size\": 4096,\n",
    "\"batch_size\": 24,\n",
    "\"num_batches_train\": 100,\n",
    "\"lr\": 3e-4\n",
    "}\n",
    "\n",
    "save_model_config_and_weights(trainer, config, config['model_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perusing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def plot_spectrogram_with_labels_and_logits(spec, ground_truth_label, logits):\n",
    "    # Apply softmax to logits to scale them between 0 and 1\n",
    "    logits_softmax = (logits.squeeze().detach().cpu()).numpy()  # Ensure logits is 1D before applying softmax\n",
    "\n",
    "    # Print the first 10 logit values\n",
    "    print(\"First 10 logit values:\", logits_softmax[:10])\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # Plot spectrogram\n",
    "    plt.imshow(spec.numpy(), aspect='auto', origin='lower')\n",
    "\n",
    "    # Overlay ground truth labels as bars at the bottom\n",
    "    times = np.arange(ground_truth_label.shape[0])\n",
    "    song_bar_height = np.full_like(ground_truth_label.numpy(), -5)  # Slightly below the spectrogram\n",
    "    not_song_bar_height = np.full_like(ground_truth_label.numpy(), -10)  # Further below for clarity\n",
    "\n",
    "    plt.fill_between(times, song_bar_height, where=ground_truth_label.numpy() > 0.5, color='green', step='mid', alpha=0.5, label='Song')\n",
    "    plt.fill_between(times, not_song_bar_height, where=ground_truth_label.numpy() <= 0.5, color='red', step='mid', alpha=0.5, label='Not Song')\n",
    "\n",
    "    # Overlay logits as a line plot\n",
    "    plt.plot(times, logits_softmax * (spec.shape[0] - 1), color='cyan', label='Logits')  # Scale logits to match spectrogram's frequency range\n",
    "\n",
    "    plt.colorbar(label='Spectrogram Intensity')\n",
    "    plt.xlabel('Time Bins')\n",
    "    plt.ylabel('Frequency Bins')\n",
    "    plt.title('Spectrogram with Ground Truth and Logits')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming `test_loader`, `model`, and `device` are defined and initialized in your code\n",
    "spec, ground_truth_label = next(iter(test_loader))  # Get a batch from your DataLoader\n",
    "\n",
    "logit = model(spec.to(device))  # Get model predictions\n",
    "\n",
    "# Use the first example in the batch for plotting\n",
    "spec = spec[0]\n",
    "ground_truth_label = ground_truth_label[0]\n",
    "logit = logit[0]  # Adjust based on your model's output shape\n",
    "\n",
    "# Remove channel dimension if present\n",
    "if spec.dim() > 2:\n",
    "    spec = spec.squeeze(0)\n",
    "\n",
    "# Plot using the function\n",
    "plot_spectrogram_with_labels_and_logits(spec.cpu(), ground_truth_label.cpu(), logit.cpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing group test: 100%|██████████| 159/159 [00:18<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for group test: {'precision': 0.009590503837704151, 'recall': 0.0035689632272958727, 'f1_score': 0.0045612384791601165, 'FER': 0.411558462386627}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing group fall_song_labeled: 100%|██████████| 340/340 [00:52<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for group fall_song_labeled: {'precision': 0.06461459602335987, 'recall': 0.023823585475443564, 'f1_score': 0.031918480997728205, 'FER': 0.48453834643281535}\n",
      "Group Metrics:\n",
      "test: {'precision': 0.009590503837704151, 'recall': 0.0035689632272958727, 'f1_score': 0.0045612384791601165, 'FER': 0.411558462386627}\n",
      "fall_song_labeled: {'precision': 0.06461459602335987, 'recall': 0.023823585475443564, 'f1_score': 0.031918480997728205, 'FER': 0.48453834643281535}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_119598/408408946.py:249: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use Agg backend for faster rendering\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_spectrogram(spec, max_length=4096):\n",
    "    \"\"\"\n",
    "    Process the spectrogram in chunks, pass through the classifier, and return the binary predictions based on BCE.\n",
    "    \"\"\"\n",
    "    # Calculate the number of chunks needed\n",
    "    num_chunks = int(np.ceil(spec.shape[1] / max_length))\n",
    "    combined_predictions = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        # Extract the chunk\n",
    "        start_idx = i * max_length\n",
    "        end_idx = min((i + 1) * max_length, spec.shape[1])\n",
    "        chunk = spec[:, start_idx:end_idx]\n",
    "        # Forward pass through the model\n",
    "        # Ensure chunk is on the correct device\n",
    "        chunk_tensor = torch.Tensor(chunk).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        \n",
    "        logits = model(chunk_tensor)\n",
    "        logits = logits.squeeze().detach().cpu()\n",
    "\n",
    "        combined_predictions.append(logits)\n",
    "\n",
    "    # Concatenate all chunks' predictions\n",
    "    final_predictions = np.concatenate(combined_predictions, axis=-1)\n",
    "\n",
    "    return final_predictions\n",
    "\n",
    "def compute_binary_sequence(song, threshold):\n",
    "    \"\"\"Convert a song signal into a binary sequence based on a threshold.\"\"\"\n",
    "    return (song >= threshold).astype(int)\n",
    "\n",
    "def moving_average(signal, window_size):\n",
    "    \"\"\"Compute the moving average of the given signal with the specified window size.\"\"\"\n",
    "    cumsum_vec = np.cumsum(np.insert(signal, 0, 0)) \n",
    "    return (cumsum_vec[window_size:] - cumsum_vec[:-window_size]) / window_size\n",
    "\n",
    "def post_process_segments(smoothed_song, threshold, min_length, pad_song):\n",
    "    \"\"\"Post-process the smoothed song to adjust segments shorter than min_length and apply padding.\"\"\"\n",
    "    processed_song = np.zeros_like(smoothed_song)\n",
    "    above_threshold = smoothed_song >= threshold\n",
    "    start = None\n",
    "\n",
    "    for i, value in enumerate(above_threshold):\n",
    "        if value and start is None:\n",
    "            start = i  # Mark the start of a new segment\n",
    "        elif not value and start is not None:\n",
    "            # Segment end found; check if it meets the min_length requirement\n",
    "            if i - start >= min_length:\n",
    "                # Apply padding to segments that meet the min_length requirement\n",
    "                start_pad = max(start - pad_song, 0)  # Ensure start_pad is not less than 0\n",
    "                end_pad = min(i + pad_song, len(above_threshold))  # Ensure end_pad does not exceed array length\n",
    "                processed_song[start_pad:end_pad] = smoothed_song[start_pad:end_pad]\n",
    "            start = None  # Reset start for the next segment\n",
    "\n",
    "    # Handle the case where a segment extends to the end of the array\n",
    "    if start is not None and len(above_threshold) - start >= min_length:\n",
    "        start_pad = max(start - pad_song, 0)\n",
    "        end_pad = min(len(above_threshold) + pad_song, len(above_threshold))\n",
    "        processed_song[start_pad:end_pad] = smoothed_song[start_pad:end_pad]\n",
    "\n",
    "    return processed_song\n",
    "\n",
    "def compute_metrics(ground_truth, predictions):\n",
    "    precision = precision_score(ground_truth, predictions, zero_division=0)\n",
    "    recall = recall_score(ground_truth, predictions, zero_division=0)\n",
    "    f1 = f1_score(ground_truth, predictions, zero_division=0)\n",
    "    # Frame Error Rate (FER): ratio of incorrect frames to total frames\n",
    "    total_frames = len(ground_truth)\n",
    "    FP = np.sum((predictions == 1) & (ground_truth == 0))\n",
    "    FN = np.sum((predictions == 0) & (ground_truth == 1))\n",
    "    FER = (FP + FN) / total_frames\n",
    "    return {'precision': precision, 'recall': recall, 'f1_score': f1, 'FER': FER}\n",
    "\n",
    "def process_file(file_path, threshold, min_length, pad_song, group_output_dir, group_name):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    metrics = None\n",
    "    plotting_data = None\n",
    "    try:\n",
    "        f = np.load(file=file_path, allow_pickle=True)\n",
    "        spec = f['s']\n",
    "        song = f['song']\n",
    "\n",
    "        # Z-score normalization\n",
    "        spec_mean = spec.mean()\n",
    "        spec_std = spec.std()\n",
    "        spec = (spec - spec_mean) / spec_std\n",
    "\n",
    "        # Process the spectrogram and get predictions\n",
    "        predictions = process_spectrogram(spec)\n",
    "\n",
    "        # Compute smoothed song\n",
    "        smoothed_song = moving_average(predictions, window_size=100)\n",
    "\n",
    "        # Post-process smoothed song\n",
    "        processed_song = post_process_segments(smoothed_song, threshold, min_length, pad_song)\n",
    "\n",
    "        # Compute metrics\n",
    "        ground_truth_binary = compute_binary_sequence(song, threshold)\n",
    "        processed_song_binary = compute_binary_sequence(processed_song, threshold)\n",
    "\n",
    "        # Ensure both sequences are the same length\n",
    "        min_length_seq = min(len(ground_truth_binary), len(processed_song_binary))\n",
    "        ground_truth_binary = ground_truth_binary[:min_length_seq]\n",
    "        processed_song_binary = processed_song_binary[:min_length_seq]\n",
    "\n",
    "        metrics = compute_metrics(ground_truth_binary, processed_song_binary)\n",
    "\n",
    "        # Collect plotting data\n",
    "        plotting_data = {\n",
    "            's': f['s'],\n",
    "            'smoothed_song': smoothed_song,\n",
    "            'processed_song': processed_song,\n",
    "            'song_length': len(song),\n",
    "            'file_name': file_name,\n",
    "            'group_output_dir': group_output_dir,\n",
    "            'song': song\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process file {file_name} in group {group_name}: {str(e)}\")\n",
    "    return metrics, plotting_data\n",
    "\n",
    "def plot_with_classification_line(src_dirs, output_dir, threshold=0.5, min_length=500, pad_song=50):\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    group_metrics = {}  # Dictionary to store metrics for each group\n",
    "\n",
    "    for src in src_dirs:\n",
    "        group_name = os.path.basename(src.rstrip('/'))\n",
    "        group_output_dir = os.path.join(output_dir, group_name)\n",
    "        if not os.path.exists(group_output_dir):\n",
    "            os.makedirs(group_output_dir)\n",
    "\n",
    "        files = [os.path.join(src, f) for f in os.listdir(src) if not f.endswith(('.bak', '.json', '.png'))]\n",
    "        metrics_list = []  # List to store metrics for this group\n",
    "        plotting_data_list = []\n",
    "\n",
    "        # Process files sequentially\n",
    "        for file_path in tqdm(files, desc=f\"Processing group {group_name}\"):\n",
    "            metrics, plotting_data = process_file(file_path, threshold, min_length, pad_song, group_output_dir, group_name)\n",
    "            if metrics:\n",
    "                metrics_list.append(metrics)\n",
    "            if plotting_data:\n",
    "                plotting_data_list.append(plotting_data)\n",
    "\n",
    "        # After processing all files, perform plotting sequentially\n",
    "        for plotting_data in plotting_data_list:\n",
    "            try:\n",
    "                s = plotting_data['s']\n",
    "                smoothed_song = plotting_data['smoothed_song']\n",
    "                processed_song = plotting_data['processed_song']\n",
    "                song_length = plotting_data['song_length']\n",
    "                file_name = plotting_data['file_name']\n",
    "                group_output_dir = plotting_data['group_output_dir']\n",
    "                song = plotting_data['song']\n",
    "\n",
    "                # Downsample the spectrogram along frequency axis only\n",
    "                s_downsampled = s[::2, :]  # Downsample frequency axis\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(10, 3))  # Smaller figure size for faster rendering\n",
    "                ax.imshow(s_downsampled, aspect='auto', origin='lower')\n",
    "                ax.set_ylabel('Frequency [Hz]')\n",
    "                ax.set_xlabel('Time [sec]')\n",
    "\n",
    "                # Plot smoothed song\n",
    "                smoothed_times = np.arange(len(smoothed_song)) + 50  # Offset for alignment\n",
    "                ax.plot(smoothed_times, smoothed_song * (s_downsampled.shape[0] - 1),\n",
    "                        color='magenta', label='Smoothed Classification Sigmoid', alpha=0.7)\n",
    "\n",
    "                # Use fill_between to shade processed song regions without looping\n",
    "                times = np.arange(len(processed_song)) + 50\n",
    "                ax.fill_between(times, -5, 0, where=processed_song > 0,\n",
    "                                color='red', alpha=0.5, step='pre')\n",
    "\n",
    "                ax.set_ylim(bottom=-5, top=s_downsampled.shape[0] - 1)  # Adjust y-limits\n",
    "                ax.set_xlim(left=0, right=s_downsampled.shape[1])  # Ensure x-limits match spectrogram\n",
    "                ax.legend(loc='upper right')\n",
    "\n",
    "                # Saving the plot with lower DPI\n",
    "                output_file_path = os.path.join(group_output_dir,\n",
    "                                                f\"{os.path.splitext(file_name)[0]}_detection.png\")\n",
    "                plt.savefig(output_file_path, bbox_inches='tight', dpi=72)  # Lower DPI speeds up saving\n",
    "                plt.close(fig)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to plot file {file_name} in group {group_name}: {str(e)}\")\n",
    "\n",
    "        # Compute average metrics for this group\n",
    "        if metrics_list:\n",
    "            avg_precision = np.mean([m['precision'] for m in metrics_list])\n",
    "            avg_recall = np.mean([m['recall'] for m in metrics_list])\n",
    "            avg_f1 = np.mean([m['f1_score'] for m in metrics_list])\n",
    "            avg_FER = np.mean([m['FER'] for m in metrics_list])\n",
    "\n",
    "            group_metrics[group_name] = {\n",
    "                'precision': avg_precision,\n",
    "                'recall': avg_recall,\n",
    "                'f1_score': avg_f1,\n",
    "                'FER': avg_FER\n",
    "            }\n",
    "\n",
    "            print(f\"Average metrics for group {group_name}: {group_metrics[group_name]}\")\n",
    "        else:\n",
    "            print(f\"No valid files were processed in group {group_name}.\")\n",
    "\n",
    "    # Plot (1 - FER) and F1 score for each group\n",
    "    groups = list(group_metrics.keys())\n",
    "    one_minus_FER = [1 - group_metrics[group]['FER'] for group in groups]\n",
    "    f1_scores = [group_metrics[group]['f1_score'] for group in groups]\n",
    "\n",
    "    x = np.arange(len(groups))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, one_minus_FER, width, label='1 - FER')\n",
    "    rects2 = ax.bar(x + width/2, f1_scores, width, label='F1 Score')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title('1 - FER and F1 Score by Group')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(groups)\n",
    "    ax.legend()\n",
    "\n",
    "    # Attach a text label above each bar in rects\n",
    "    def autolabel(rects):\n",
    "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate(f'{height:.2f}',\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return the group metrics\n",
    "    return group_metrics\n",
    "\n",
    "# Example usage\n",
    "src_dirs = [\n",
    "    \"/media/george-vengrovski/disk2/training_song_detector/labeled_song_dataset/test\",\n",
    "    # \"/media/george-vengrovski/disk2/training_song_detector/labeled_song_dataset/train\",\n",
    "    # \"/media/george-vengrovski/disk2/training_song_detector/nerve_transection_labeled\",\n",
    "    \"/media/george-vengrovski/disk2/training_song_detector/fall_song_labeled\"\n",
    "]\n",
    "output_dir = \"/media/george-vengrovski/disk2/training_song_detector/validation_results\"\n",
    "\n",
    "group_metrics = plot_with_classification_line(src_dirs, output_dir, threshold=0.5, min_length=500, pad_song=50)\n",
    "\n",
    "# Print the overall metrics\n",
    "print(\"Group Metrics:\")\n",
    "for group_name, metrics in group_metrics.items():\n",
    "    print(f\"{group_name}: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for plotting\n",
    "\n",
    "def process_spectrogram(spec, max_length=4096):\n",
    "    \"\"\"\n",
    "    Process the spectrogram in chunks, pass through the classifier, and return the binary predictions based on BCE.\n",
    "    \"\"\"\n",
    "    # Calculate the number of chunks needed\n",
    "    num_chunks = int(np.ceil(spec.shape[1] / max_length))\n",
    "    combined_predictions = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        # Extract the chunk\n",
    "        start_idx = i * max_length\n",
    "        end_idx = min((i + 1) * max_length, spec.shape[1])\n",
    "        chunk = spec[:, start_idx:end_idx]\n",
    "        # Forward pass through the model\n",
    "        # Ensure chunk is on the correct device\n",
    "        chunk_tensor = torch.Tensor(chunk).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        \n",
    "        logits = model(chunk_tensor)\n",
    "        logits = logits.squeeze().detach().cpu()\n",
    "\n",
    "        combined_predictions.append(logits)\n",
    "\n",
    "    # Concatenate all chunks' predictions\n",
    "    final_predictions = np.concatenate(combined_predictions, axis=-1)\n",
    "\n",
    "    return final_predictions\n",
    "\n",
    "def process_files(src):\n",
    "    \"\"\"\n",
    "    Process each file in the directory, reshape predictions, and overwrite the original files with the processed data.\n",
    "    \"\"\"\n",
    "    files = os.listdir(src)\n",
    "    for file in tqdm(files, desc=\"Processing files\"):  # Wrap the loop with tqdm for progress tracking\n",
    "        file_path = os.path.join(src, file)\n",
    "\n",
    "        if file.endswith('.bak'):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Load the spectrogram from the file\n",
    "            f = np.load(file_path, allow_pickle=True)\n",
    "            spec = f['s']\n",
    "            song = f['song']\n",
    "\n",
    "            # Z-score normalization\n",
    "            spec_mean = spec.mean()\n",
    "            spec_std = spec.std()\n",
    "            spec = (spec - spec_mean) / spec_std\n",
    "\n",
    "            # Process the spectrogram and get predictions\n",
    "            predictions = process_spectrogram(spec)\n",
    "\n",
    "            # Overwrite the original file with the spectrogram and predictions\n",
    "            np.savez(file_path, s=spec, predictions=predictions, song=song)  \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process file {file}: {str(e)}\")\n",
    "\n",
    "src = \"/media/george-vengrovski/disk2/training_song_detector/fall_song_labeled\"\n",
    "process_files(src)\n",
    "\n",
    "# Plotting the results in bar graphs\n",
    "def plot_group_metrics(group_metrics):\n",
    "    groups = list(group_metrics.keys())\n",
    "    metrics = ['precision', 'recall', 'f1_score', 'FER']\n",
    "    \n",
    "    # Initialize the figure and axes\n",
    "    fig, axes = plt.subplots(1, len(metrics), figsize=(20, 5))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [group_metrics[group][metric] for group in groups]\n",
    "        axes[i].bar(groups, values)\n",
    "        axes[i].set_title(metric)\n",
    "        axes[i].set_xlabel('Groups')\n",
    "        axes[i].set_ylabel(metric)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "src_dirs = [\n",
    "    \"/media/george-vengrovski/disk2/training_song_detector/test\",\n",
    "    \"/media/george-vengrovski/disk2/training_song_detector/validation_test_set\"\n",
    "]\n",
    "output_dir = \"/media/george-vengrovski/disk2/training_song_detector/validation_results\"\n",
    "\n",
    "group_metrics = plot_with_classification_line(src_dirs, output_dir, threshold=0.5, min_length=500, pad_song=50)\n",
    "\n",
    "# Print the overall metrics\n",
    "print(\"Group Metrics:\")\n",
    "for group_name, metrics in group_metrics.items():\n",
    "    print(f\"{group_name}: {metrics}\")\n",
    "\n",
    "# Plot the group metrics\n",
    "plot_group_metrics(group_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_binary_sequence(song, threshold):\n",
    "    \"\"\"Convert a song signal into a binary sequence based on a threshold.\"\"\"\n",
    "    return (song >= threshold).astype(int)\n",
    "\n",
    "def compute_levenshtein_distance(ground_truth, predictions):\n",
    "    \"\"\"Compute Levenshtein distance between ground truth and prediction sequences.\"\"\"\n",
    "    return Levenshtein.distance(ground_truth.tostring(), predictions.tostring())\n",
    "\n",
    "def moving_average(signal, window_size):\n",
    "    \"\"\"Compute the moving average of the given signal with the specified window size.\"\"\"\n",
    "    cumsum_vec = np.cumsum(np.insert(signal, 0, 0)) \n",
    "    return (cumsum_vec[window_size:] - cumsum_vec[:-window_size]) / window_size\n",
    "\n",
    "def post_process_segments(smoothed_song, threshold, min_length, pad_song):\n",
    "    \"\"\"Post-process the smoothed song to adjust segments shorter than min_length and apply padding.\"\"\"\n",
    "    processed_song = np.zeros_like(smoothed_song)\n",
    "    above_threshold = smoothed_song >= threshold\n",
    "    start = None\n",
    "\n",
    "    for i, value in enumerate(above_threshold):\n",
    "        if value and start is None:\n",
    "            start = i  # Mark the start of a new segment\n",
    "        elif not value and start is not None:\n",
    "            # Segment end found; check if it meets the min_length requirement\n",
    "            if i - start >= min_length:\n",
    "                # Apply padding to segments that meet the min_length requirement\n",
    "                start_pad = max(start - pad_song, 0)  # Ensure start_pad is not less than 0\n",
    "                end_pad = min(i + pad_song, len(above_threshold))  # Ensure end_pad does not exceed array length\n",
    "                processed_song[start_pad:end_pad] = smoothed_song[start_pad:end_pad]\n",
    "            start = None  # Reset start for the next segment\n",
    "\n",
    "    # Handle the case where a segment extends to the end of the array\n",
    "    if start is not None and len(above_threshold) - start >= min_length:\n",
    "        start_pad = max(start - pad_song, 0)\n",
    "        end_pad = min(len(above_threshold) + pad_song, len(above_threshold))\n",
    "        processed_song[start_pad:end_pad] = smoothed_song[start_pad:end_pad]\n",
    "\n",
    "    return processed_song\n",
    "\n",
    "def plot_with_classification_line(src, output_dir, threshold=0.5, min_length=500, pad_song=50):\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    files = os.listdir(src)\n",
    "    levenshtein_distances = []  # Store Levenshtein distances\n",
    "\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(src, file_name)\n",
    "\n",
    "        if file_name.endswith('.bak') or file_name.endswith('.json') or file_name.endswith('.png'):\n",
    "            continue\n",
    "\n",
    "        f = np.load(file=file_path, allow_pickle=True)\n",
    "\n",
    "        predictions = f['predictions']\n",
    "        song = f['song']\n",
    "\n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(figsize=(20, 6))\n",
    "        ax.imshow(f['s'], aspect='auto', origin='lower')\n",
    "        ax.set_ylabel('Frequency [Hz]')\n",
    "        ax.set_xlabel('Time [sec]')\n",
    "\n",
    "        # Compute and plot smoothed line\n",
    "        smoothed_song = moving_average(predictions, window_size=100)\n",
    "        smoothed_times = np.arange(len(smoothed_song)) + 50  # Offset for alignment\n",
    "        ax.plot(smoothed_times, smoothed_song * (f['s'].shape[0] - 1), color='magenta', label='Smoothed Classification Sigmoid', alpha=0.7)\n",
    "\n",
    "        # Post-process smoothed song to adjust short segments and apply padding\n",
    "        processed_song = post_process_segments(smoothed_song, threshold, min_length, pad_song)\n",
    "\n",
    "        # Add a color bar below the spectrogram based on the processed song data\n",
    "        for i in range(len(processed_song)):\n",
    "            color = 'red' if processed_song[i] > 0 else 'blue'\n",
    "            ax.axhspan(ymin=-5, ymax=0, xmin=(i + 50) / len(song), xmax=(i + 51) / len(song), color=color)\n",
    "\n",
    "        ax.set_ylim(bottom=-5)  # Adjust y-axis to include the new bar\n",
    "\n",
    "        # Adjust legend to include both lines\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "        # Saving the plot\n",
    "        output_file_path = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}_detection.png\")\n",
    "        plt.savefig(output_file_path, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Compute Levenshtein distance between post-processed predictions and ground truth\n",
    "        ground_truth_binary = compute_binary_sequence(song, threshold)\n",
    "        processed_song_binary = compute_binary_sequence(processed_song, threshold)\n",
    "\n",
    "        levenshtein_distance = compute_levenshtein_distance(ground_truth_binary, processed_song_binary)\n",
    "\n",
    "        # Store Levenshtein distance\n",
    "        levenshtein_distances.append(levenshtein_distance)\n",
    "\n",
    "        print(f\"Levenshtein distance for {file_name}: {levenshtein_distance}\")\n",
    "\n",
    "    # Compute and print average Levenshtein distance\n",
    "    if levenshtein_distances:\n",
    "        avg_levenshtein_distance = np.mean(levenshtein_distances)\n",
    "        print(f\"Average Levenshtein distance: {avg_levenshtein_distance}\")\n",
    "    else:\n",
    "        print(\"No valid files were processed.\")\n",
    "\n",
    "# Example usage\n",
    "src = \"/media/george-vengrovski/disk2/training_song_detector/validation_test_set\"\n",
    "output_dir = \"/media/george-vengrovski/disk2/training_song_detector/validation_test_set\"\n",
    "plot_with_classification_line(src, output_dir, threshold=0.5, min_length=500, pad_song=50) ~~~ This is my validation notebook .... change levenstein distance to f1 metric and just basic FER ... also instead of reading and writing back to file ... when reading the file, process it, compute metrics and save metrics to memory. Allow for multiple src directories which  are processed and compared as seperate groups!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetybert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
